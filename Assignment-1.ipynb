{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_PROJECT = \"myprojectname\"\n",
    "WANDB_ENTITY = \"myname\"\n",
    "DATASET = \"fashion_mnist\"\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 4\n",
    "LOSS = \"cross_entropy\"\n",
    "OPTIMIZER = \"sgd\"\n",
    "LEARNING_RATE = 0.1\n",
    "MOMENTUM = 0.5\n",
    "BETA = 0.5\n",
    "BETA1 = 0.5\n",
    "BETA2 = 0.5\n",
    "EPSILON = 1e-6\n",
    "WEIGHT_DECAY = 0.0\n",
    "WEIGHT_INIT = \"random\"\n",
    "NUM_LAYERS = 1\n",
    "HIDDEN_SIZE = 4\n",
    "ACTIVATION = \"sigmoid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "\n",
    "# wandb.init(project=WANDB_PROJECT, entity=WANDB_ENTITY)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Download the fashion-MNIST dataset and plot 1 sample image for each class as shown in the grid using wandb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "# Load the data\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot one image from each class\n",
    "# for i in range(10):\n",
    "#     plt.subplot(2, 5, i+1)\n",
    "#     plt.imshow(x_train[y_train == i][0], cmap='gray')\n",
    "#     plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNeuralNetwork():\n",
    "    def __init__(self, neurons, hidden_layers, input_size, output_size, activation_function, weight_init):\n",
    "        self.neurons, self.hidden_layers = neurons, hidden_layers\n",
    "        self.weights, self.biases = [], []\n",
    "        self.input_size, self.output_size = input_size, output_size\n",
    "        self.activation_function = activation_function\n",
    "        self.weight_init = weight_init\n",
    "        self.pre_activation, self.post_activation = [], []\n",
    "        self.output_activation_function = \"softmax\"\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        self.weights.append(np.random.randn(self.input_size, self.neurons))\n",
    "        for _ in range(self.hidden_layers-1):\n",
    "            self.weights.append(np.random.randn(self.neurons, self.neurons))\n",
    "        self.weights.append(np.random.randn(self.neurons, self.output_size))\n",
    "\n",
    "        if self.weight_init == \"Xavier\":\n",
    "            for i in range(len(self.weights)):\n",
    "                self.weights[i] = self.weights[i] / np.sqrt(self.weights[i].shape[0])\n",
    "\n",
    "    def initiate_biases(self):\n",
    "        for _ in range(self.hidden_layers):\n",
    "            self.biases.append(np.random.randn(self.neurons))\n",
    "        self.biases.append(np.random.randn(self.output_size))\n",
    "    \n",
    "    def activation(self, x):\n",
    "        # x is a matrix of size (batch_size, neurons)\n",
    "        if self.activation_function == \"sigmoid\":\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "        elif self.activation_function == \"tanh\":\n",
    "            return np.tanh(x)\n",
    "        elif self.activation_function == \"ReLU\":\n",
    "            return np.maximum(0, x)\n",
    "        else:\n",
    "            raise Exception(\"Invalid activation function\")\n",
    "    \n",
    "    def output_activation(self, x):\n",
    "        if self.output_activation_function == \"softmax\":\n",
    "            return softmax(x, axis=1)\n",
    "        else:\n",
    "            raise Exception(\"Invalid output activation function\")\n",
    "    \n",
    "    def output_matrix(self, x):\n",
    "        # x is a matrix of size (batch_size, input_size)\n",
    "        self.pre_activation = []\n",
    "        self.post_activation = []\n",
    "        self.pre_activation.append(x)\n",
    "        self.post_activation.append(x)\n",
    "\n",
    "        for i in range(self.hidden_layers):\n",
    "            y = np.dot(self.pre_activation[i], self.weights[i]) + self.biases[i]\n",
    "            self.pre_activation.append(y)\n",
    "            self.post_activation.append(self.activation(y))\n",
    "            \n",
    "        y = np.dot(self.pre_activation[-1], self.weights[-1]) + self.biases[-1]\n",
    "        self.pre_activation.append(y)\n",
    "        self.post_activation.append(self.output_activation(y))\n",
    "        return self.post_activation[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y, y_pred):\n",
    "    # y is a matrix of size (batch_size, output_size)\n",
    "    # y_pred is a matrix of size (batch_size, output_size)\n",
    "    if LOSS == \"cross_entropy\":\n",
    "        return -np.sum(y * np.log(y_pred)) / y.shape[0]\n",
    "    elif LOSS == \"mse\":\n",
    "        return np.sum((y - y_pred)**2) / y.shape[0]\n",
    "    else:\n",
    "        raise Exception(\"Invalid loss function\")\n",
    "\n",
    "def loss_derivative(y, y_pred):\n",
    "    # y is a matrix of size (batch_size, output_size)\n",
    "    # y_pred is a matrix of size (batch_size, output_size)\n",
    "    if LOSS == \"cross_entropy\":\n",
    "        return -y / y_pred\n",
    "    elif LOSS == \"mse\":\n",
    "        return 2 * (y_pred - y)\n",
    "    else:\n",
    "        raise Exception(\"Invalid loss function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
